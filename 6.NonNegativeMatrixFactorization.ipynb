{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open the following link with a new tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/nzhinusoftcm/review-on-collaborative-filtering/blob/master/6.NonNegativeMatrixFactorization.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization for Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusl like Matrix Factorization (MF) [(Yehuda Koren et al., 2009)](https://ieeexplore.ieee.org/document/5197422), Non-negative Matrix Factorization (NMF in short) factors the rating matrix $R$ in two matrices in such a way that $R = PQ^{\\top}$.\n",
    "\n",
    "### One limitation of Matrix Factorization\n",
    "\n",
    "$P$ and $Q$ values in MF are non interpretable since their components can take arbitrary (positive and negative) values.\n",
    "\n",
    "### Particulariy of Non-negative Matrix Factorization\n",
    "\n",
    "NMF [(Lee and Seung, 1999)](http://www.dm.unibo.it/~simoncin/nmfconverge.pdf) allows the reconstruction of $P$ and $Q$ in such a way that $P,Q \\ge 0$. Constrain $P$ and $Q$ values to be taken from $[0,1]$ allows  a probabilistic interpretation\n",
    "\n",
    "- Latent factors represent groups of users who share the same tastes,\n",
    "- The value  $P_{u,l}$  represents the probability that user $u$ belongs to the group $l$ of users and \n",
    "- The value $Q_{l,i}$ represents the probability that users in the group $l$  likes item $i$.\n",
    "\n",
    "### Objective function\n",
    "\n",
    "With the Euclidian distance, the NMF objective function is defined by\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{2}\\sum_{(u,i) \\in \\kappa}||R_{u,i} - P_uQ_i^{\\top}||^2 + \\lambda_P||P_u||^2 + \\lambda_Q||Q_i||^2\n",
    "\\end{equation}\n",
    "\n",
    "The goal is to minimize the cost function $J$ by optimizing parameters $P$ and $Q$, with $\\lambda_P$ and $\\lambda_Q$ the regularizer parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative update rule\n",
    "\n",
    "According [(Lee and Seung, 1999)](https://www.nature.com/articles/44565.pdf), to the multiplicative update rule for $P$ and $Q$ are as follows :\n",
    "\n",
    "\\begin{equation}\n",
    "P \\leftarrow P \\cdot \\frac{RQ}{PQ^{\\top}Q}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Q \\leftarrow Q \\cdot \\frac{R^{\\top}P}{QP^{\\top}P}\n",
    "\\end{equation}\n",
    "\n",
    "However, since $R$ is a sparse matrix, we need to update each $P_u$ according to existing ratings of user $u$. Similarily, we need to update $Q_i$ according to existing ratings on item $i$. Hence :\n",
    "\n",
    "\\begin{equation}\n",
    "P_{u,k} \\leftarrow P_{u,k} \\cdot \\frac{\\sum_{i \\in I_u}Q_{i,k}\\cdot r_{u,i}}{\\sum_{i \\in I_u}Q_{i,k}\\cdot \\hat{r}_{u,i} + \\lambda_P|I_u|P_{u,k}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "Q_{i,k} \\leftarrow Q_{i,k} \\cdot \\frac{\\sum_{u \\in U_i}P_{u,k}\\cdot r_{u,i}}{\\sum_{u \\in U_i}P_{u,k}\\cdot \\hat{r}_{u,i} + \\lambda_Q|U_i|Q_{i,k}}\n",
    "\\end{equation}\n",
    "\n",
    "Where\n",
    "- $P_{u,k}$ is the $k^{th}$ latent factor of $P_u$\n",
    "- $Q_{i,k}$ is the $k^{th}$ latent factor of $Q_i$\n",
    "- $I_u$ the of items rated by user $u$\n",
    "- $U_i$ the set of users who rated item $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
    "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
    "    !unzip recsys.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import useful packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requirements\n",
    "\n",
    "```\n",
    "matplotlib==3.2.2\n",
    "numpy==1.18.1\n",
    "pandas==1.0.5\n",
    "python==3.6.10\n",
    "scikit-learn==0.23.1\n",
    "scipy==1.5.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsys.preprocessing import mean_ratings\n",
    "from recsys.preprocessing import normalized_ratings\n",
    "from recsys.preprocessing import  encode_data\n",
    "from recsys.preprocessing import split_data\n",
    "from recsys.preprocessing import rating_matrix\n",
    "from recsys.preprocessing import get_examples\n",
    "from recsys.preprocessing import scale_ratings\n",
    "\n",
    "from recsys.datasets import mlLastedSmall\n",
    "from recsys.datasets import ml1m\n",
    "from recsys.datasets import ml100k\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "ratings, movies = mlLastedSmall.load()\n",
    "\n",
    "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
    "raw_examples, raw_labels = get_examples(ratings, labels_column=\"rating\")\n",
    "\n",
    "# train test split\n",
    "(train_examples, test_examples), (train_labels, test_labels) = split_data(examples=raw_examples, labels=raw_labels)\n",
    "\n",
    "examples = (train_examples, test_examples)\n",
    "labels = (train_labels, test_labels)\n",
    "\n",
    "# encode train and test examples\n",
    "(X_train, X_test), (y_train, y_test), (uencoder, iencoder) = encode_data(ratings, examples=examples, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.userid = uencoder.transform(ratings.userid.to_list())\n",
    "ratings.itemid = iencoder.transform(ratings.itemid.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonNegativeMF:\n",
    "    \n",
    "    def __init__(self, ratings, m, n, K=10, lambda_P=0.01, lambda_Q=0.01):\n",
    "        \n",
    "        np.random.seed(32)\n",
    "        \n",
    "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
    "        self.ratings = ratings\n",
    "        self.K = K\n",
    "        self.P = np.random.rand(m, K)\n",
    "        self.Q = np.random.rand(n, K)\n",
    "        \n",
    "        # hyperparameter initialization\n",
    "        self.lambda_P = lambda_P\n",
    "        self.lambda_Q = lambda_Q\n",
    "        \n",
    "        # training history\n",
    "        self.history = {\n",
    "            \"epochs\":[],\n",
    "            \"loss\":[],\n",
    "            \"val_loss\":[],\n",
    "        }\n",
    "    \n",
    "    def print_training_parameters(self):\n",
    "        print('Training Matrix Factorization Model ...')\n",
    "        print(f'k={self.K}')\n",
    "        \n",
    "    def mae(self,  x_train, y_train):\n",
    "        \"\"\"\n",
    "        returns the Mean Absolute Error\n",
    "        \"\"\"\n",
    "        # number of training exemples\n",
    "        M = x_train.shape[0]\n",
    "        error = 0\n",
    "        for pair, r in zip(x_train, y_train):\n",
    "            u, i = pair\n",
    "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
    "        return error/M\n",
    "    \n",
    "    def ratings_by_this_user(self, userid):\n",
    "        return self.ratings.loc[self.ratings.userid==userid]\n",
    "    \n",
    "    def ratings_on_this_items(self, itemid):\n",
    "        return self.ratings.loc[self.ratings.itemid==itemid]\n",
    "    \n",
    "    def update_rule(self, u, i, error):\n",
    "        I = self.ratings_by_this_user(u)\n",
    "        U = self.ratings_on_this_items(i)    \n",
    "        \n",
    "        for k in range(self.K):\n",
    "            \n",
    "            num_uk = self.P[u,k] * np.sum(np.multiply(self.Q[I.itemid.to_list(),k], I.rating.to_list()))\n",
    "            dem_uk = np.sum(np.multiply(\n",
    "                self.Q[I.itemid.to_list(),k], \n",
    "                np.dot(self.P[u], self.Q[I.itemid.to_list()].T))\n",
    "                           ) + self.lambda_P * len(I) * self.P[u,k]\n",
    "            self.P[u,k] = num_uk / dem_uk\n",
    "                \n",
    "            num_ik = self.Q[i,k] * np.sum(np.multiply(self.P[U.userid.to_list(),k], U.rating.to_list()))\n",
    "            dem_ik = np.sum(np.multiply(\n",
    "                self.P[U.userid.to_list(),k], \n",
    "                np.dot(self.P[U.userid.to_list()], self.Q[i].T))\n",
    "                           ) + self.lambda_Q * len(U) * self.Q[i,k]\n",
    "            self.Q[i,k] = num_ik / dem_ik\n",
    "                \n",
    "    \n",
    "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
    "        if epoch == 1 or epoch % steps == 0 :\n",
    "                print(\"epoch {}/{} - loss : {} - val_loss : {}\".format(\n",
    "                    epoch, epochs, round(error,3), round(val_error,3)))\n",
    "                \n",
    "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
    "\n",
    "        self.print_training_parameters()\n",
    "        x_test, y_test = validation_data\n",
    "        for epoch in range(1, epochs+1):\n",
    "            for pair, r in zip(x_train, y_train):\n",
    "                u,i = pair\n",
    "                r_hat = np.dot(self.P[u], self.Q[i])\n",
    "                e = abs(r - r_hat)\n",
    "                self.update_rule(u, i, e)                \n",
    "            # training and validation error  after this epochs\n",
    "            error = self.mae(x_train, y_train)\n",
    "            val_error = self.mae(x_test, y_test)\n",
    "            self.update_history(epoch, error, val_error)\n",
    "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def update_history(self, epoch, error, val_error):\n",
    "        self.history['epochs'].append(epoch)\n",
    "        self.history['loss'].append(error)\n",
    "        self.history['val_loss'].append(val_error)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):        \n",
    "        error = self.mae(x_test, y_test)\n",
    "        print(f\"validation error : {round(error,3)}\")\n",
    "        print('MAE : ', error)        \n",
    "        return error\n",
    "      \n",
    "    def predict(self, userid, itemid):\n",
    "        u = uencoder.transform([userid])[0]\n",
    "        i = iencoder.transform([itemid])[0]\n",
    "        r = np.dot(self.P[u], self.Q[i])\n",
    "        return r\n",
    "\n",
    "    def recommend(self, userid, N=30):\n",
    "        # encode the userid\n",
    "        u = uencoder.transform([userid])[0]\n",
    "\n",
    "        # predictions for users userid on all product\n",
    "        predictions = np.dot(self.P[u], self.Q.T)\n",
    "\n",
    "        # get the indices of the top N predictions\n",
    "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
    "\n",
    "        # decode indices to get their corresponding itemids\n",
    "        top_items = iencoder.inverse_transform(top_idx)\n",
    "\n",
    "        # take corresponding predictions for top N indices\n",
    "        preds = predictions[top_idx]\n",
    "\n",
    "        return top_items, preds   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Matrix Factorization Model ...\n",
      "k=10\n",
      "epoch 1/10 - loss : 0.779 - val_loss : 0.801\n",
      "epoch 2/10 - loss : 0.775 - val_loss : 0.797\n",
      "epoch 3/10 - loss : 0.773 - val_loss : 0.796\n",
      "epoch 4/10 - loss : 0.772 - val_loss : 0.795\n",
      "epoch 5/10 - loss : 0.771 - val_loss : 0.795\n",
      "epoch 6/10 - loss : 0.771 - val_loss : 0.795\n",
      "epoch 7/10 - loss : 0.77 - val_loss : 0.795\n",
      "epoch 8/10 - loss : 0.77 - val_loss : 0.795\n",
      "epoch 9/10 - loss : 0.77 - val_loss : 0.794\n",
      "epoch 10/10 - loss : 0.769 - val_loss : 0.794\n"
     ]
    }
   ],
   "source": [
    "m = ratings['userid'].nunique()   # total number of users\n",
    "n = ratings['itemid'].nunique()   # total number of items\n",
    "\n",
    "# create and train the model\n",
    "NMF = NonNegativeMF(ratings, m, n, K=10,  lambda_P=0.5, lambda_Q=0.5)\n",
    "history = NMF.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error : 0.794\n",
      "MAE :  0.7943610363378308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7943610363378308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMF.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate NMF on ML100k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ratings, movies = ml100k.load()\n",
    "\n",
    "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
    "raw_examples, raw_labels = get_examples(ratings, labels_column=\"rating\")\n",
    "\n",
    "# train test split\n",
    "(train_examples, test_examples), (train_labels, test_labels) = split_data(examples=raw_examples, labels=raw_labels)\n",
    "\n",
    "examples = (train_examples, test_examples)\n",
    "labels = (train_labels, test_labels)\n",
    "\n",
    "# encode train and test examples\n",
    "(X_train, X_test), (y_train, y_test), (uencoder, iencoder) = encode_data(ratings, examples=examples, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.userid = uencoder.transform(ratings.userid.to_list())\n",
    "ratings.itemid = iencoder.transform(ratings.itemid.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Matrix Factorization Model ...\n",
      "k=10\n",
      "epoch 1/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 2/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 3/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 4/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 5/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 6/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 7/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 8/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 9/10 - loss : 0.866 - val_loss : 0.865\n",
      "epoch 10/10 - loss : 0.866 - val_loss : 0.865\n"
     ]
    }
   ],
   "source": [
    "m = ratings['userid'].nunique()   # total number of users\n",
    "n = ratings['itemid'].nunique()   # total number of items\n",
    "\n",
    "# create and train the model\n",
    "NMF = NonNegativeMF(ratings, m, n, K=10,  lambda_P=0.5, lambda_Q=0.5)\n",
    "history = NMF.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error : 0.865\n",
      "MAE :  0.8647139758177113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8647139758177113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMF.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. Daniel D. Lee & H. Sebastian Seung (1999). [Learning the parts of objects by non-negative matrix factorization](https://www.nature.com/articles/44565)\n",
    "2. Deng Cai et al. (2008). [Non-negative Matrix Factorization on Manifold](https://ieeexplore.ieee.org/document/4781101)\n",
    "3. Yu-Xiong Wang and Yu-Jin Zhang (2011). [Non-negative Matrix Factorization: a Comprehensive Review](https://ieeexplore.ieee.org/document/6165290)\n",
    "4. Nicolas Gillis (2014). [The Why and How of Nonnegative Matrix Factorization](https://arxiv.org/pdf/1401.5226.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/carmel-wenga-871876178/\">Carmel WENGA</a>, Applied Machine Learning Research Engineer | <a href=\"https://shoppinglist.cm/fr/\">ShoppingList</a>, Nzhinusoft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecSys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
